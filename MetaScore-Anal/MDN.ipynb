{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Normal\n",
    "import numpy as np # Will be used for generating points for plotting\n",
    "from models.gatedgcn import GatedGCN\n",
    "data_path = './dataset/pdbbind/demo.pt'\n",
    "data = torch.load(data_path,weights_only=False)\n",
    "ligmodel = GatedGCN(in_channels=41, \n",
    "                    edge_features=10, \n",
    "                    num_hidden_channels=128, \n",
    "                    residual=True,\n",
    "                    dropout_rate=0.15,\n",
    "                    equivstable_pe=False,\n",
    "                    num_layers=6\n",
    "                    )\n",
    "protmodel = GatedGCN(in_channels=41, \n",
    "                    edge_features=5, \n",
    "                    num_hidden_channels=128, \n",
    "                    residual=True,\n",
    "                    dropout_rate=0.15,\n",
    "                    equivstable_pe=False,\n",
    "                    num_layers=6\n",
    "                    )\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dim, dropout_rate):\n",
    "        super(MLP, self).__init__()\n",
    "        self.mlp = nn.Sequential(nn.Linear(in_channels*2, hidden_dim), \n",
    "\t\t\t\t\t\t\t\tnn.BatchNorm1d(hidden_dim), \n",
    "\t\t\t\t\t\t\t\tnn.ELU(), \n",
    "\t\t\t\t\t\t\t\tnn.Dropout(p=dropout_rate)) \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "class z_pi_layer(nn.Module):\n",
    "    def __init__(self, hidden_dim=128, n_gaussians=10):\n",
    "        super(z_pi_layer, self).__init__()\n",
    "        self.z_pi = nn.Linear(hidden_dim, n_gaussians)\n",
    "    def forward(self, x):\n",
    "        return self.z_pi(x)\n",
    "class z_sigma_layer(nn.Module):\n",
    "    def __init__(self, hidden_dim=128, n_gaussians=10):\n",
    "        super(z_sigma_layer, self).__init__()\n",
    "        self.z_sigma = nn.Linear(hidden_dim, n_gaussians)\n",
    "    def forward(self, x):\n",
    "        return self.z_sigma(x)\n",
    "class z_mu_layer(nn.Module):\n",
    "    def __init__(self, hidden_dim=128, n_gaussians=10):\n",
    "        super(z_mu_layer, self).__init__()\n",
    "        self.z_mu = nn.Linear(hidden_dim, n_gaussians)\n",
    "    def forward(self, x):\n",
    "        return self.z_mu(x)\n",
    "class atom_types_layer(nn.Module):\n",
    "    def __init__(self, in_channels=128, n=17):\n",
    "        super(atom_types_layer, self).__init__()\n",
    "        self.atom_types = nn.Linear(in_channels, n)\n",
    "    def forward(self, x):\n",
    "        return self.atom_types(x)\n",
    "class bond_types_layer(nn.Module):\n",
    "    def __init__(self, in_channel=128, n=4):\n",
    "        super(bond_types_layer, self).__init__()\n",
    "        self.bond_types = nn.Linear(in_channel*2, n)\n",
    "    def forward(self, x):\n",
    "        return self.bond_types(x)\n",
    "mlp = MLP(128, 128, 0.15)\n",
    "z_pi = z_pi_layer(128, 10)\n",
    "z_sigma = z_sigma_layer(128, 10)\n",
    "z_mu = z_mu_layer(128, 10)\n",
    "atom_types = atom_types_layer(128, 17)\n",
    "bond_types = bond_types_layer(128, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Batch\n",
    "batchsize = 8\n",
    "prot_batch = []\n",
    "lig_batch = []\n",
    "label_batch = []\n",
    "flag = 0\n",
    "for key, value in data.items():\n",
    "    prot_batch.append(value['prot'])\n",
    "    lig_batch.append(value['lig'])\n",
    "    label_batch.append(float(value['label']))\n",
    "    flag += 1\n",
    "    if flag == batchsize:\n",
    "        break\n",
    "prot_batch = Batch.from_data_list(prot_batch)\n",
    "lig_batch = Batch.from_data_list(lig_batch)\n",
    "label_batch = torch.tensor(label_batch)\n",
    "h_l = ligmodel(lig_batch)\n",
    "h_t = protmodel(prot_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter_add\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "h_l_x, l_mask = to_dense_batch(h_l.x, h_l.batch, fill_value=0)\n",
    "h_t_x, t_mask = to_dense_batch(h_t.x, h_t.batch, fill_value=0)\n",
    "h_l_pos, _ = to_dense_batch(h_l.pos, h_l.batch, fill_value=0)\n",
    "h_t_pos, _ = to_dense_batch(h_t.pos, h_t.batch, fill_value=0)\n",
    "(B, N_l, C_out), N_t = h_l_x.size(), h_t_x.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([18681, 256]),\n",
       " torch.Size([8, 49, 101, 256]),\n",
       " torch.Size([8, 49, 101]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_l_x_new = h_l_x.unsqueeze(-2)\n",
    "h_l_x_new2 = h_l_x_new.repeat(1, 1, N_t, 1) # [B, N_l, N_t, C_out]\n",
    "h_l_x_new2.shape\n",
    "h_t_x_new = h_t_x.unsqueeze(-3)\n",
    "h_t_x_new2 = h_t_x_new.repeat(1, N_l, 1, 1) # [B, N_l, N_t, C_out]\n",
    "h_t_x_new2.shape\n",
    "C = torch.cat((h_l_x_new2, h_t_x_new2), -1)\n",
    "C.shape\n",
    "C_mask = l_mask.view(B, N_l, 1) & t_mask.view(B, 1, N_t)\n",
    "C_mask.shape\n",
    "C_new = C[C_mask]\n",
    "C_new.shape,C.shape,C_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 7, 7, 7])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_new2 = mlp(C_new)\n",
    "C_new2.shape\n",
    "C_batch = torch.tensor(range(B)).unsqueeze(-1).unsqueeze(-1)\n",
    "C_batch.shape\n",
    "C_batch_new = C_batch.repeat(1, N_l, N_t)[C_mask]\n",
    "C_batch_new.shape\n",
    "C_batch_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([18681, 10]), torch.Size([18681, 10]), torch.Size([18681, 10]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "pi = F.softmax(z_pi(C_new2), -1)\n",
    "sigma = F.elu(z_sigma(C_new2))+1.1\n",
    "mu = F.elu(z_mu(C_new2))+1\n",
    "pi.shape,sigma.shape,mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 17]), torch.Size([476, 4]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atom_types = atom_types(h_l.x)\n",
    "bond_types = bond_types(torch.cat([h_l.x[h_l.edge_index[0]], h_l.x[h_l.edge_index[1]]], axis=1))  \n",
    "atom_types.shape,bond_types.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2.0631, -1.6908, -0.0284,  ..., -1.4472,  1.8577,  3.6292],\n",
       "         [ 0.7991, -0.5083, -0.3321,  ..., -0.0709,  1.5080,  2.6271],\n",
       "         [ 2.8874,  0.1504,  1.0486,  ..., -2.1823,  1.6224,  3.5007],\n",
       "         ...,\n",
       "         [ 2.8269, -0.3445,  1.3712,  ...,  1.9708,  0.6048,  5.2988],\n",
       "         [ 1.6809, -1.6907, -0.4642,  ..., -1.2399,  2.0318,  2.0042],\n",
       "         [ 3.5060, -0.2919,  1.8847,  ...,  0.5114, -0.5795,  3.9267]],\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[-0.6892, -1.5002, -1.1214, -0.0823],\n",
       "         [-1.2390, -1.5962, -4.0807,  0.2000],\n",
       "         [-1.8250, -2.2734, -2.5978, -0.0464],\n",
       "         ...,\n",
       "         [ 0.2831, -1.8221,  2.1551, -1.0913],\n",
       "         [-2.8723, -0.3263, -3.0241,  1.0681],\n",
       "         [ 0.8589, -0.7306,  2.0615, -1.3952]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atom_types,bond_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_euclidean_distances_matrix(X, Y):\n",
    "    X = X.double()\n",
    "    Y = Y.double()\n",
    "    dists = -2 * torch.bmm(X, Y.permute(0, 2, 1)) + torch.sum(Y**2,axis=-1).unsqueeze(1) + torch.sum(X**2, axis=-1).unsqueeze(-1)\t\n",
    "    return torch.nan_to_num((dists**0.5).view(B, N_l,-1,24),10000).min(axis=-1)#[0]\n",
    "dist = compute_euclidean_distances_matrix(h_l_pos, h_t_pos.view(B,-1,3))#[C_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 49, 3]), torch.Size([8, 101, 24, 3]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_l_pos.shape,h_t_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2424, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h_t_pos.view(B,-1,3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2424, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h_t_pos.view(B,-1,3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2424, 3])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_t_pos.view(B,-1,3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2424, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h_t_pos.view(B,-1,3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2424, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h_t_pos.view(B,-1,3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mdn_loss_fn(pi, sigma, mu, y, eps1=1e-10, eps2=1e-10):\n",
    "    \"\"\"\n",
    "    Calculates the Mixture Density Network loss.\n",
    "    Args:\n",
    "        pi (torch.Tensor): Mixture coefficients (batch_size, num_components).\n",
    "        sigma (torch.Tensor): Standard deviations of Gaussian components (batch_size, num_components).\n",
    "                           Must be positive.\n",
    "        mu (torch.Tensor): Means of Gaussian components (batch_size, num_components).\n",
    "        y (torch.Tensor): Target values (batch_size, 1) or (batch_size,).\n",
    "        eps1 (float): Small epsilon for pi log stability.\n",
    "        eps2 (float): Small epsilon for final probability log stability.\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]:\n",
    "            - loss: The negative log-likelihood loss for each sample in the batch (batch_size,).\n",
    "            - prob: The probability of y for each sample (batch_size,).\n",
    "    \"\"\"\n",
    "    normal = Normal(mu, sigma)\n",
    "    loglik = normal.log_prob(y.expand_as(normal.loc))\n",
    "    prob = (torch.log(pi + eps1) + loglik).exp().sum(dim=1)\n",
    "    loss = -torch.log(prob + eps2)\n",
    "    return loss, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 49, 101])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metascore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
